import { OllamaModel } from "shared/types/OllamaModel";

export const OllamaModels: OllamaModel[] = [
  {
    name: 'mxbai-embed-large:latest',
    type: "Embedding"
  },
  {
    name: 'nomic-embed-text:latest',
    type: "Embedding"
  },
  {
    name: 'deepseek-r1:latest',
    type: "LLM"
  },
  {
    name: 'llama3:latest',
    type: "LLM"
  },
  {
    name: 'llama3.3:latest',
    type: "LLM"
  },
  {
    name: 'llama3.2:latest',
    type: "LLM"
  },
  {
    name: 'llama3.1:latest',
    type: "LLM"
  },
  {
    name: 'mistral:latest',
    type: "LLM"
  }
  ,
  {
    name: 'qwen2.5:latest',
    type: "LLM"
  }
  ,
  {
    name: 'qwen2.5-coder:latest',
    type: "LLM"
  }
  ,
  {
    name: 'gemma2:latest',
    type: "LLM"
  }
  ,
  {
    name: 'llama2:latest',
    type: "LLM"
  },
  {
    name: 'phi3:latest',
    type: "LLM"
  }
  ,
  {
    name: 'codellama:latest',
    type: "LLM"
  }
  ,
  {
    name: 'gemma3:latest',
    type: "LLM"
  }
  ,
  {
    name: 'qwq:latest',
    type: "Reasoning"
  }

]
